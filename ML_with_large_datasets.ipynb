{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fb76f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier  as RF\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import datetime\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf02ef8c",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def map5eval(preds, dtrain):\n",
    "    actual = dtrain.get_label()\n",
    "    predicted = preds.argsort(axis=1)[:,-np.arange(5)]\n",
    "    metric = 0.\n",
    "    for i in range(5):\n",
    "        metric += np.sum(actual==predicted[:,i])/(i+1)\n",
    "    metric /= actual.shape[0]\n",
    "    return 'MAP@5', -metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86442773",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = \"../data/train.csv\"\n",
    "COLS = ['site_name', 'user_location_region', 'is_package', 'srch_adults_cnt', 'srch_children_cnt','srch_destination_id', 'hotel_market', 'hotel_country', 'hotel_cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ddcad56",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['objective'] = 'multi:softprob'\n",
    "params['eval_metric'] = 'mlogloss'\n",
    "params['num_class'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f341218",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def read_pandas_df(num_rows=100000, chunk_size=100000):\n",
    "    \n",
    "    tot_rows = 0\n",
    "    df_train = pd.DataFrame(columns=COLS)\n",
    "    train_chunk = pd.read_csv(DATA_FILE, chunksize=chunk_size)\n",
    "    i = 0\n",
    "    for chunk in train_chunk:\n",
    "        df_train = pd.concat([df_train, chunk[chunk['is_booking'] == 1][COLS]])\n",
    "        tot_rows += df_train.shape[0]\n",
    "        i = i + 1\n",
    "        if i % 10 == 0:\n",
    "            print(\"Rows loaded: \" + str(i / 10) + \"mn\")\n",
    "        \n",
    "        if (num_rows - tot_rows) < 1000:\n",
    "            break\n",
    "    \n",
    "    return df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13ae4010",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def build_RF_with_sklearn(df):\n",
    "    for column in df:\n",
    "        df[column] = df[column].astype(str).astype(int)\n",
    "\n",
    "    # print(df_train.shape())\n",
    "    X = df.drop(['hotel_cluster'],axis=1)\n",
    "    y = df['hotel_cluster'].values\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    start = datetime.datetime.now()\n",
    "    clf = RF(n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    end = datetime.datetime.now()\n",
    "    time_taken = (end-start).total_seconds()/60\n",
    "    num_rows = X.shape[0]\n",
    "    print('Training {:,} rows took {} minutes with all cores'.format(num_rows, time_taken))\n",
    "    return time_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "066394a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_outputs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "701fab9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 715,472 rows took 1.0411282833333333 minutes with all cores\n",
      "Rows loaded: 1.0mn\n",
      "Training 795,034 rows took 1.0911258666666666 minutes with all cores\n",
      "Rows loaded: 1.0mn\n",
      "Training 876,862 rows took 1.2374210499999998 minutes with all cores\n",
      "Rows loaded: 1.0mn\n",
      "Training 957,961 rows took 1.32568415 minutes with all cores\n",
      "Rows loaded: 1.0mn\n",
      "Training 1,039,190 rows took 1.5135286833333335 minutes with all cores\n",
      "Rows loaded: 1.0mn\n",
      "Training 1,120,113 rows took 1.6149491833333334 minutes with all cores\n",
      "Rows loaded: 1.0mn\n",
      "Training 1,199,323 rows took 2.0890350833333335 minutes with all cores\n",
      "Rows loaded: 1.0mn\n",
      "Training 1,278,563 rows took 2.2376370166666666 minutes with all cores\n",
      "Rows loaded: 1.0mn\n",
      "Training 1,356,603 rows took 2.3325253 minutes with all cores\n",
      "Rows loaded: 1.0mn\n",
      "Training 1,356,603 rows took 2.3295823500000004 minutes with all cores\n",
      "Rows loaded: 1.0mn\n",
      "Training 1,434,612 rows took 2.3590483333333334 minutes with all cores\n",
      "Rows loaded: 1.0mn\n",
      "Training 1,513,961 rows took 2.4693372333333334 minutes with all cores\n",
      "Rows loaded: 1.0mn\n",
      "Training 1,513,961 rows took 2.5167815166666667 minutes with all cores\n",
      "Rows loaded: 1.0mn\n",
      "Rows loaded: 2.0mn\n",
      "Training 1,593,149 rows took 2.628327533333333 minutes with all cores\n",
      "Rows loaded: 1.0mn\n",
      "Rows loaded: 2.0mn\n",
      "Training 1,671,108 rows took 2.77205715 minutes with all cores\n",
      "Rows loaded: 1.0mn\n",
      "Rows loaded: 2.0mn\n",
      "Training 1,671,108 rows took 2.7804972500000003 minutes with all cores\n",
      "Rows loaded: 1.0mn\n",
      "Rows loaded: 2.0mn\n",
      "Training 1,750,718 rows took 2.9705949499999997 minutes with all cores\n"
     ]
    }
   ],
   "source": [
    "rows = [i*1e6 for i in range(3,20)]\n",
    "data = []\n",
    "current_nrows = 0\n",
    "for r in rows:\n",
    "    try:\n",
    "        df = read_pandas_df(num_rows=r, chunk_size=1000000)\n",
    "        time_taken = build_RF_with_sklearn(df)\n",
    "        pandas_outputs.append({'TimeTaken': round(time_taken, 4), 'NumRows': df.shape[0]})\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47877cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d5e7c5",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def build_model_with_sparkMLlib(nrows):\n",
    "    \n",
    "    # Load and parse the data file, converting it to a DataFrame.\n",
    "    schema = \"`site_name` INT, `user_location_region` INT, `is_package` INT,`srch_adults_cnt` INT, `srch_children_cnt` INT,`srch_destination_id` INT, `hotel_market` INT, `hotel_country` INT,`hotel_cluster` INT\"\n",
    "    sdf = spark.read.schema(schema).csv(data)\n",
    "    sdf = sdf.dropna()\n",
    "    sdf_sample = sdf.sample(fraction=0.01).cache()\n",
    "    \n",
    "    \n",
    "    feature_cols = list(set(train_cols)-set(['hotel_cluster']))\n",
    "    print(feature_cols)\n",
    "    assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
    "    transformed_train_data = assembler.transform(sdf_sample).cache()\n",
    "    \n",
    "    (train, test) = transformed_train_data.randomSplit([0.8, 0.2])\n",
    "    \n",
    "    rf = RandomForestClassifier(labelCol='hotel_cluster', featuresCol='features')\n",
    "    rf.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f156c34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"SimpleApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae25eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and parse the data file, converting it to a DataFrame.\n",
    "schema = \"`site_name` INT, `user_location_region` INT, `is_package` INT,`srch_adults_cnt` INT, `srch_children_cnt` INT,`srch_destination_id` INT, `hotel_market` INT, `hotel_country` INT,`hotel_cluster` INT\"\n",
    "sdf = spark.read.schema(schema).csv(data)\n",
    "sdf = sdf.dropna()\n",
    "sdf_sample = sdf.sample(fraction=0.01).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c613413e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = list(set(train_cols)-set(['hotel_cluster']))\n",
    "print(feature_cols)\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
    "transformed_train_data = assembler.transform(sdf_sample).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f23a084",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train, test) = transformed_train_data.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e63b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol='hotel_cluster', featuresCol='features')\n",
    "rf.fit(train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
